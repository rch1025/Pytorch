{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d6906c7d-d546-447c-861e-758e5a4928fd",
   "metadata": {},
   "source": [
    "# 신경망 모델 구성하기\n",
    "- 신경망은 데이터에 대한 연산을 수행하는 계층(layer)과 모듈(module)로 구성되어 있다. \n",
    "- torch.nn 네임스페이스는 신경망을 구성하는데 필요한 모든 구성 요소를 제공한다.\n",
    "- 파이토치의 모든 모듈은 nn.Moudle의 하위 클래스이다.\n",
    "- 신경망은 다른 모듈(계층;layer)로 구성된 모듈이다.\n",
    "- 이러한 중첩된 구조는 복잡한 아키텍처를 쉽게 구축하고 관리할 수 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ecd458d-3aed-4f79-ac21-319d78fbc784",
   "metadata": {},
   "source": [
    "### FashionMNIST 데이터셋의 이미지들을 분류하는 신경망 구성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "79e16f8e-c575-4ca7-bdcc-e33d44642e21",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a6cb3cdd-04a6-4c2d-9f45-fa1d5bd41e63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n"
     ]
    }
   ],
   "source": [
    "\"\"\"학습을 위한 장치 얻기\"\"\"\n",
    "## GPU 사용\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Using {device} device\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "682a58f3-e99a-40c7-9fdd-77997047182e",
   "metadata": {},
   "source": [
    "-----"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8908c134-2c58-4705-94bc-605bf6eff737",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 클래스 정의하기\n",
    "- 신경망 모델을 nn.Module의 하위클래스로 정의하고, __init__에서 신경망 계층들을 초기화한다. \n",
    "- nn.Module을 상속받은 모든 클래스는 forward 메소드에 입력 데이터에 대한 연산들을 구현한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d3861099-735f-460c-b4e6-1e494d363550",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(NeuralNetwork, self).__init__()\n",
    "        ## flatten layer\n",
    "        self.flatten = nn.Flatten()\n",
    "        \n",
    "        ## linear layer\n",
    "        self.linear_relu_stack = nn.Sequential(\n",
    "        nn.Linear(28*28, 512),\n",
    "        nn.ReLU(),\n",
    "        nn.Linear(512, 512),\n",
    "        nn.ReLU(),\n",
    "        nn.Linear(512, 10),\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.flatten(x)\n",
    "        logits = self.linear_relu_stack(x)\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b078e43f-e7d4-40f8-819f-b611a0fa9abe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NeuralNetwork(\n",
      "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "  (linear_relu_stack): Sequential(\n",
      "    (0): Linear(in_features=784, out_features=512, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=512, out_features=10, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "\"\"\"NeuralNetwork의 인스턴스(instance)를 생성하고, 이를 device로 이동한 뒤 구조(structure)를 출력한다.\"\"\"\n",
    "model = NeuralNetwork().to(device)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4df4fea6-988e-48d3-84b4-be6737e27e18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted class: tensor([2], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "모델을 사용하기 위해 입력 데이터를 전달한다. 이는 일부 백그라운드 연산들과 함께 모델의 forward를 실행한다.(model.forward()를 직접 호출하지 말기)\n",
    "\n",
    "모델에 입력을 호출하면 각 target class에 대한 raw 예측값이 있는 10차원 텐서가 반환된다. raw 예측값을 nn.Softmax 모듈의 인스턴스에 통과시켜 예측 확률을 얻는다.\n",
    "\"\"\"\n",
    "\n",
    "X = torch.rand(1, 28, 28, device = device)\n",
    "\n",
    "## model(X)을 통해 raw 예측값 출력\n",
    "logits = model(X)\n",
    "\n",
    "## raw 예측값을 Softmax()에 넣기\n",
    "pred_probab = nn.Softmax(dim=1)(logits)\n",
    "y_pred = pred_probab.argmax(1)\n",
    "print(f\"Predicted class: {y_pred}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92e8c802-e255-4b95-8631-4a42c4627f95",
   "metadata": {},
   "source": [
    "--------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e7ced46-cffc-4938-be13-ebf260e8bc94",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 모델 계층(Layer)\n",
    "- FashionMNIST 모델의 계층들을 살펴보겠다. 이를 위해 28*28 size의 이미지 3개로 구성된 minibatch를 가져와 신경망을 통과할 때 어떤 일이 발생하는지 보자."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "01e2ce7c-c2f9-4781-ade5-a4918354088e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 28, 28])\n"
     ]
    }
   ],
   "source": [
    "input_image = torch.rand(3, 28, 28)\n",
    "print(input_image.size())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e44523a-20a9-487e-8fa9-8e2dd75ea09c",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e52445a-4e87-4101-9828-71d53066d7af",
   "metadata": {},
   "source": [
    "### nn.Flatten()\n",
    "- nn.Flatten() 계층을 초기화하여 각 28*28의 2D 이미지를 784 픽셀 값을 갖는 연속된 배열로 변환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "30dc083a-794c-47b5-9b16-a8a037d41aed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 784])\n"
     ]
    }
   ],
   "source": [
    "\"\"\"dim=0의 minibatch 차원은 그대로 유지됨\"\"\"\n",
    "flatten = nn.Flatten()\n",
    "flat_image = flatten(input_image)\n",
    "print(flat_image.size())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a33973a5-107d-47b6-9a0d-71a586ca59bb",
   "metadata": {},
   "source": [
    "--------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "984544b4-61bd-41fb-a550-b8a1a119caff",
   "metadata": {},
   "source": [
    "### nn.Linear\n",
    "- 선형 계층은 저장된 weight와 bias를 사용하여 입력에 선형 변환을 적용하는 모듈이다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f73f15ae-809b-4d80-bf2f-10be6da33ebf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 20])\n"
     ]
    }
   ],
   "source": [
    "\"\"\"dim=0의 minibatch 차원은 그대로 유지됨\"\"\"\n",
    "## Linear layer 하나만 만드릭\n",
    "layer1 = nn.Linear(in_features = 28*28, out_features = 20)\n",
    "hidden1 = layer1(flat_image)\n",
    "print(hidden1.size())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cb35a3a-d28b-4903-b692-ea683b05f37e",
   "metadata": {},
   "source": [
    "--------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35f2a599-9fa2-4974-b3f0-02e6c2aae02d",
   "metadata": {},
   "source": [
    "### nn.ReLU\n",
    "- 비선형 활성화는 모델의 입력과 출력 사이에 복잡한 관계(mapping)를 만든다.\n",
    "- 비선형성을 도입하여 신경망이 다양한 현상을 학습할 수 있도록 도움\n",
    "- 이 모델에서는 nn.ReLU를 선형 계층들 사이에 사용하지만, 모델을 만들 때는 비선형성을 가진 다른 활성화를 도입할 수도 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4c29bb3c-98b0-4938-a3f7-7e7caa7d72fa",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before ReLU: tensor([[ 0.1483,  0.1651,  0.3092, -0.1367,  0.1695,  0.9259,  0.4148, -0.0642,\n",
      "          0.4373,  0.4728, -0.5555, -0.2597, -0.6533,  0.4282,  0.0091, -0.5497,\n",
      "          0.1929,  0.0291, -0.3109, -0.3549],\n",
      "        [ 0.1188, -0.1149, -0.0461, -0.2117,  0.1255,  0.8773,  0.4396, -0.0485,\n",
      "         -0.0879,  0.3923, -0.6350, -0.3957, -0.4411,  0.3937,  0.4923, -0.3180,\n",
      "          0.1492, -0.0120, -0.3423, -0.1487],\n",
      "        [ 0.0724,  0.0730,  0.3313, -0.1869,  0.0412,  0.8972,  0.4337,  0.0970,\n",
      "          0.1788,  0.1512, -0.5526, -0.3061, -0.5508,  0.4478,  0.1720, -0.5585,\n",
      "          0.7487,  0.3660, -0.5037, -0.0148]], grad_fn=<AddmmBackward>)\n",
      "\n",
      "\n",
      "After ReLU: tensor([[0.1483, 0.1651, 0.3092, 0.0000, 0.1695, 0.9259, 0.4148, 0.0000, 0.4373,\n",
      "         0.4728, 0.0000, 0.0000, 0.0000, 0.4282, 0.0091, 0.0000, 0.1929, 0.0291,\n",
      "         0.0000, 0.0000],\n",
      "        [0.1188, 0.0000, 0.0000, 0.0000, 0.1255, 0.8773, 0.4396, 0.0000, 0.0000,\n",
      "         0.3923, 0.0000, 0.0000, 0.0000, 0.3937, 0.4923, 0.0000, 0.1492, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0724, 0.0730, 0.3313, 0.0000, 0.0412, 0.8972, 0.4337, 0.0970, 0.1788,\n",
      "         0.1512, 0.0000, 0.0000, 0.0000, 0.4478, 0.1720, 0.0000, 0.7487, 0.3660,\n",
      "         0.0000, 0.0000]], grad_fn=<ReluBackward0>)\n"
     ]
    }
   ],
   "source": [
    "print(f\"Before ReLU: {hidden1}\\n\\n\")\n",
    "hidden1 = nn.ReLU()(hidden1)\n",
    "print(f\"After ReLU: {hidden1}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0f71877-9ec8-4b94-9c6e-c778ad1560f2",
   "metadata": {},
   "source": [
    "--------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64871db3-94b0-4f9a-b514-7f4040695ffa",
   "metadata": {},
   "source": [
    "### nn.Sequential\n",
    "- nn.Sequential은 순서를 갖는 모듈의 컨테이너이다. \n",
    "- 데이터는 정의된 것과 같은 순서로 모든 모듈들을 통해 전달된다.\n",
    "- 순차 컨테이너를 사용하여 아래의 seq_modules와 같은 신경망을 빠르게 만들 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e5e54ae5-52a7-4ede-9772-2fbb17533442",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 10])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seq_modules = nn.Sequential(\n",
    "flatten,\n",
    "layer1,\n",
    "nn.ReLU(),\n",
    "nn.Linear(20, 10)\n",
    ")\n",
    "\n",
    "input_image = torch.rand(3, 28, 28)\n",
    "logits = seq_modules(input_image)\n",
    "logits.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "13fbb517-850f-47b2-8ab8-ff26434cdcc6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0717, 0.1048, 0.1241, 0.1011, 0.1106, 0.1069, 0.0833, 0.0732, 0.1182,\n",
       "         0.1061],\n",
       "        [0.0691, 0.0982, 0.1495, 0.0983, 0.0987, 0.1012, 0.0884, 0.0712, 0.1187,\n",
       "         0.1066],\n",
       "        [0.0740, 0.1013, 0.1409, 0.0890, 0.0998, 0.1191, 0.0866, 0.0670, 0.1103,\n",
       "         0.1120]], grad_fn=<SoftmaxBackward>)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"dim 매개변수는 값의 합이 1이 되는 차원을 의미한다.\"\"\"\n",
    "softmax = nn.Softmax(dim=1)\n",
    "pred_probab = softmax(logits)\n",
    "pred_probab"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "feab76e1-87d8-4aed-908c-5fe663a15542",
   "metadata": {},
   "source": [
    "-----"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bbb0474-5d20-41f0-8a42-75c551a8998c",
   "metadata": {},
   "source": [
    "### 모델 매개변수\n",
    "- 신경망 내부의 많은 계층들은 매개변수화 된다. 즉, 학습 중에 최적화되는 가중치와 편형과 연관지어진다. \n",
    "- nn.Module을 상속하면 모델 객체 내부의 모든 필드들이 자동으로 추적되며, 모델의 parameters() 및 named_parameters() 메소드로 모든 매개변수에 접근할 수 있게 된다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c9bcda63-57e2-4ed6-a348-2a2160350af4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model structure: NeuralNetwork(\n",
      "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "  (linear_relu_stack): Sequential(\n",
      "    (0): Linear(in_features=784, out_features=512, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=512, out_features=10, bias=True)\n",
      "  )\n",
      ")\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\"\"\"모델 구조\"\"\"\n",
    "print(f\"Model structure: {model}\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "50831b30-df02-4379-8f2c-19ec1f0fb5e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer: linear_relu_stack.0.weight | Size: torch.Size([512, 784]) | Values : tensor([[-0.0113,  0.0210,  0.0057,  ...,  0.0242, -0.0182,  0.0136],\n",
      "        [ 0.0265, -0.0356,  0.0002,  ...,  0.0279, -0.0236,  0.0275]],\n",
      "       device='cuda:0', grad_fn=<SliceBackward>) \n",
      "\n",
      "Layer: linear_relu_stack.0.bias | Size: torch.Size([512]) | Values : tensor([ 0.0026, -0.0120], device='cuda:0', grad_fn=<SliceBackward>) \n",
      "\n",
      "Layer: linear_relu_stack.2.weight | Size: torch.Size([512, 512]) | Values : tensor([[ 0.0221,  0.0184, -0.0209,  ...,  0.0161, -0.0377, -0.0424],\n",
      "        [ 0.0320,  0.0424, -0.0185,  ...,  0.0337, -0.0294, -0.0101]],\n",
      "       device='cuda:0', grad_fn=<SliceBackward>) \n",
      "\n",
      "Layer: linear_relu_stack.2.bias | Size: torch.Size([512]) | Values : tensor([-0.0048,  0.0229], device='cuda:0', grad_fn=<SliceBackward>) \n",
      "\n",
      "Layer: linear_relu_stack.4.weight | Size: torch.Size([10, 512]) | Values : tensor([[ 0.0174,  0.0219, -0.0176,  ...,  0.0424, -0.0328,  0.0219],\n",
      "        [ 0.0176, -0.0330, -0.0269,  ...,  0.0097,  0.0208,  0.0225]],\n",
      "       device='cuda:0', grad_fn=<SliceBackward>) \n",
      "\n",
      "Layer: linear_relu_stack.4.bias | Size: torch.Size([10]) | Values : tensor([ 0.0016, -0.0137], device='cuda:0', grad_fn=<SliceBackward>) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "\"\"\"각 layer 별로 weight와 bias가 번갈아가면서 나타난다.\"\"\"\n",
    "for name, param in model.named_parameters():\n",
    "    print(f\"Layer: {name} | Size: {param.size()} | Values : {param[:2]} \\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40968b96-665c-4890-a370-ba6c8495528c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch-gpu",
   "language": "python",
   "name": "torch-gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
