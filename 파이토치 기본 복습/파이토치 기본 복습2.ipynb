{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9cde1921-864b-4722-b2d2-c0f2faded42e",
   "metadata": {},
   "source": [
    "### Join(cat, stack) 기능 사용 방법\n",
    "- 파이토치에서 torch.cat(seq, dim)을 이용하여 concaternate 연산을 할 수 있다.\n",
    "- dim은 concaternate할 방향을 정한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "843062ae-5a26-4a5f-8b63-0e275c216436",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "06f97e02-cd5e-4d25-8b05-15b1f9e0648d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "z1 : tensor([[ 1.,  2.,  3.],\n",
      "        [ 4.,  5.,  6.],\n",
      "        [-1., -2., -3.],\n",
      "        [-4., -5., -6.]], device='cuda:0') \n",
      "\n",
      "\n",
      "z2 : tensor([[ 1.,  2.,  3., -1., -2., -3.],\n",
      "        [ 4.,  5.,  6., -4., -5., -6.]], device='cuda:0') \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\"\"\"torch.cat(seq, dim)\"\"\"\n",
    "x = torch.cuda.FloatTensor([[1,2,3], [4,5,6]])\n",
    "y = torch.cuda.FloatTensor([[-1,-2,-3], [-4,-5,-6]])\n",
    "z1 = torch.cat([x,y], dim=0)\n",
    "print('z1 :', z1, '\\n\\n')\n",
    "\n",
    "z2 = torch.cat([x,y], dim=1)\n",
    "print('z2 :', z2, '\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f6429c86-c0d2-43d1-9677-3995d13add8b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[1., 2., 3.],\n",
       "         [4., 5., 6.]],\n",
       "\n",
       "        [[1., 2., 3.],\n",
       "         [4., 5., 6.]],\n",
       "\n",
       "        [[1., 2., 3.],\n",
       "         [4., 5., 6.]],\n",
       "\n",
       "        [[1., 2., 3.],\n",
       "         [4., 5., 6.]]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"torch.stack()\"\"\"\n",
    "x = torch.FloatTensor([[1,2,3], [4,5,6]])\n",
    "x_stack = torch.stack([x,x,x,x], dim=0)\n",
    "x_stack"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dd4b453-66ec-4734-8269-abf66a0873ee",
   "metadata": {},
   "source": [
    "### Slicing 기능 사용 방법\n",
    "- slicing 기능은 텐서를 몇 개의 부분으로 나눈다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "85fb8250-f386-40c4-bc17-85103c46cd8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 1.,  2.,  3.],\n",
      "        [ 4.,  5.,  6.],\n",
      "        [-1., -2., -3.],\n",
      "        [-4., -5., -6.]], device='cuda:0') \n",
      "\n",
      "\n",
      "tensor([[1., 2., 3.],\n",
      "        [4., 5., 6.]], device='cuda:0')\n",
      "tensor([[-1., -2., -3.],\n",
      "        [-4., -5., -6.]], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "\"\"\"torch.chunk(tensor, chunks, dim=0) // torch.split(tensor, split_size, dim=0)\"\"\"\n",
    "\n",
    "x_1, x_2 = torch.chunk(z1, 2, dim=0)\n",
    "y_1, y_2, y_3 = torch.chunk(z1, 3, dim=1)\n",
    "print(z1, '\\n\\n')\n",
    "print(x_1)\n",
    "print(x_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8f615a5d-1010-4d62-a4dd-573dccfdacf7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 1.],\n",
      "        [ 4.],\n",
      "        [-1.],\n",
      "        [-4.]], device='cuda:0')\n",
      "tensor([[ 2.],\n",
      "        [ 5.],\n",
      "        [-2.],\n",
      "        [-5.]], device='cuda:0')\n",
      "tensor([[ 3.],\n",
      "        [ 6.],\n",
      "        [-3.],\n",
      "        [-6.]], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "print(y_1)\n",
    "print(y_2)\n",
    "print(y_3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acd52b8a-c54d-4466-afef-761650d6e604",
   "metadata": {},
   "source": [
    "### squeezing 기능 사용 방법\n",
    "- squeeze 함수를 사용하면 차원 중에 1로 되어 있는 것을 압축할 수 있다.\n",
    "- 차원이 1이면 사실 불필요한 차원일 수 있기에 이럴 때 사용한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "fbcf53f4-f1d6-4703-b1cf-53eb11ed997b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 1, 2, 1, 2])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"torch.squeeze(input, dim)\"\"\"\n",
    "## dim을 지정하지 않으면 dimension이 1인 모든 차원을 압축하고 dim을 지정하면 지정한 dim만 압축한다.\n",
    "    # dim=1이라는 소리는 1번째 차원이 아니라 차원의 크기 자체가 1로 되어있는 것을 의미\n",
    "x = torch.zeros(2, 1, 2, 1, 2)\n",
    "x.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6aaf9890-78fc-4b55-b172-f2697c7efd6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 2, 2])\n"
     ]
    }
   ],
   "source": [
    "y = torch.squeeze(x)\n",
    "print(y.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c576d9b1-ba55-45b0-b15d-491505adeaff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 1, 2, 1, 2])\n"
     ]
    }
   ],
   "source": [
    "## 0번째 차원이 1이 아니기에 압축되지 않음\n",
    "y = torch.squeeze(x, 0)\n",
    "print(y.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "61c705eb-cfbc-4946-a5ad-d8cb5515c239",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 1, 2, 2])\n"
     ]
    }
   ],
   "source": [
    "## 3번째 차원이 1이기에 압축됨\n",
    "y = torch.squeeze(x, 3)\n",
    "print(y.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "9d898247-bc8a-46b2-9f59-2866676b3986",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 3, 4]) \n",
      "\n",
      "\n",
      "torch.Size([1, 2, 3, 4]) \n",
      "\n",
      "\n",
      "torch.Size([1, 1, 2, 3, 4]) \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "torch.unsqueeze()\n",
    "- unsqueeze 함수를 사용하면 차원을 추가할 수 있다. squeeze와 정확히 반대이다.\n",
    "- unsqueeze 함수는 차원을 반드시 입력해야 한다.\n",
    "\"\"\"\n",
    "\n",
    "x = torch.zeros(2,3,4)\n",
    "print(x.size(), '\\n\\n')\n",
    "\n",
    "## 0번째 위치의 차원이 늘어난다.\n",
    "x = torch.unsqueeze(x, 0)\n",
    "print(x.size(), '\\n\\n')\n",
    "\n",
    "x = torch.unsqueeze(x, 1)\n",
    "print(x.size(), '\\n\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "927c2088-a8a0-4108-8df8-348b6ad762cd",
   "metadata": {},
   "source": [
    "### Initialization : 초기화 방법"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "d7373fbc-40f0-4dfc-9b55-f510cfb0ebb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.9601, 2.2129, 7.1025, 2.5845],\n",
      "        [4.6904, 3.7599, 6.3068, 0.1367],\n",
      "        [6.4853, 3.1847, 0.2838, 5.1375]]) \n",
      "\n",
      "\n",
      "tensor([[ 0.1646,  0.2772,  0.2458,  0.0221],\n",
      "        [ 0.2133, -0.4355,  0.0363,  0.1279],\n",
      "        [-0.1255, -0.1652,  0.0762, -0.2310]]) \n",
      "\n",
      "\n",
      "tensor([[3.1415, 3.1415, 3.1415, 3.1415],\n",
      "        [3.1415, 3.1415, 3.1415, 3.1415],\n",
      "        [3.1415, 3.1415, 3.1415, 3.1415]])\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "init.uniform 함수를 사용하면 uniform 또는 normal 분포의 초기화 Tensor를 만들 수 있다.\n",
    "또는 상수 형태를 바로 만들 수도 있다.\n",
    "\"\"\"\n",
    "import torch.nn.init as init\n",
    "x1 = init.uniform_(torch.FloatTensor(3,4), a=0, b=9)\n",
    "print(x1, '\\n\\n')\n",
    "\n",
    "x2 = init.normal_(torch.FloatTensor(3,4), std=0.2)\n",
    "print(x2, '\\n\\n')\n",
    "\n",
    "## 상수 형태의 분포\n",
    "x3 = init.constant_(torch.FloatTensor(3,4), 3.1415)\n",
    "print(x3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0579d447-b168-4536-8912-0ccba082eaf1",
   "metadata": {},
   "source": [
    "### Math Operation\n",
    "- `dot`: vector 내적\n",
    "- `mv`: 행렬과 벡터의 곱\n",
    "- `mm`: 행렬과 행렬의 곱\n",
    "- `matmul`: 인수의 종류에 따라서 자동으로 dot, mm, mv를 선택"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "1937dc96-f030-499a-b132-5847d85a63e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"텐서의 행렬곱: .matmul(), @\"\"\"\n",
    "a = torch.tensor([1,2,3,4,5,6]).view(3,2)\n",
    "b = torch.tensor([9,8,7,6,5,4]).view(2,3)\n",
    "ab = torch.matmul(a,b)\n",
    "ab = a@b # @ 연산자를 이용하여 간단하게 행렬곱을 표현할 수 있음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "83606031-68dd-4a20-bec5-224acdb1a893",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 2.,  4.,  6.],\n",
      "        [ 8., 10., 12.]])\n"
     ]
    }
   ],
   "source": [
    "\"\"\"텐서의 산술 연산 방법 -> element wise 연산 방법을 의미\n",
    "1. torch.add()\n",
    "2. + 연산자 \"\"\"\n",
    "x1 = torch.FloatTensor([[1,2,3],\n",
    "                        [4,5,6]])\n",
    "x2 = torch.FloatTensor([[1,2,3],\n",
    "                        [4,5,6]])\n",
    "add = x1 + x2 # add = torch.add(x1,x2) 또한 가능합니다.\n",
    "print(add)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "b3644e4c-02c3-4ab8-b73f-3ea15e4cde7d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[11., 12., 13.],\n",
       "        [14., 15., 16.]])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\" +연산자를 이용한 broadcasting 또는 torch.add() with broadcasting\"\"\"\n",
    "x1 = torch.FloatTensor([[1,2,3],\n",
    "                        [4,5,6]])\n",
    "x1 + 10 # torch.add(x1, 10) 또한 가능합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "91794702-f96b-409f-b127-bab13ab51eb4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.,  4.,  9.],\n",
       "        [16., 25., 36.]])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\" *연산자 또는 torch.mul()\"\"\"\n",
    "x1 = torch.FloatTensor([[1,2,3],\n",
    "                        [4,5,6]])\n",
    "x2 = torch.FloatTensor([[1,2,3],\n",
    "                        [4,5,6]])\n",
    "x1*x2 # torch.mul(x1,x2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "bcd8bac4-c95f-48f9-b87d-5bf7a8274424",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[10., 20., 30.],\n",
       "        [40., 50., 60.]])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\" *연산자를 이용한 broadcasting 또는 torch.mul() with broadcasting \"\"\"\n",
    "x1 = torch.FloatTensor([[1,2,3],\n",
    "                        [4,5,6]])\n",
    "x1 * 10\n",
    "torch.mul(x1, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "3fb5be66-75cc-4443-ba01-70d15e408834",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 1., 1.],\n",
       "        [1., 1., 1.]])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\" /연산자 또는 torch.div() \"\"\"\n",
    "x1 = torch.FloatTensor([[1,2,3],\n",
    "                        [4,5,6]])\n",
    "x2 = torch.FloatTensor([[1,2,3],\n",
    "                        [4,5,6]])\n",
    "x1/x2 # torch.div(x1, x2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "b3478284-24ee-4830-8e16-b0989513684f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.2000, 0.4000, 0.6000],\n",
       "        [0.8000, 1.0000, 1.2000]])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\" /연산자를 이용한 broadcsting 또는 torch.div() with broadcasting \"\"\"\n",
    "x1 = torch.FloatTensor([[1,2,3],\n",
    "                        [4,5,6]])\n",
    "x1 / 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "fc5747e1-bda4-47af-b352-fbabaab1eb0a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.,  4.,  9.],\n",
       "        [16., 25., 36.]])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\" power 연산 : torch.pow(input,exponent) \"\"\"\n",
    "x1 = torch.FloatTensor([ [1,2,3], \n",
    "                        [4,5,6] ])\n",
    "x1**2 # torch.pow(x1,2)\n",
    "torch.pow(x1, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "06aa201d-6297-4939-b544-64470611d9e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[  2.7183,   7.3891,  20.0855],\n",
       "        [ 54.5981, 148.4132, 403.4288]])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\" exponential 연산 : torch.exp(tensor,out=None) \"\"\"\n",
    "x1 = torch.FloatTensor([ [1,2,3], \n",
    "                        [4,5,6] ])\n",
    "torch.exp(x1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "653c98d5-53d8-4338-a4f4-e083d465d079",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0000, 0.6931, 1.0986],\n",
       "        [1.3863, 1.6094, 1.7918]])"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\" torch.log(input, out=None) -> natural logarithm \"\"\"\n",
    "x1 = torch.FloatTensor([ [1,2,3], \n",
    "                        [4,5,6] ])\n",
    "torch.log(x1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "1832ac3d-054c-4b4f-aac8-248d4b4b70f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 5])"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\" torch.mm(mat1, mat2) -> 행렬끼리의 곱셈 \"\"\"\n",
    "## Tensor 행렬의 곱을 연산하므로 shape이 잘 맞아야 연산이 가능하다.\n",
    "x1 = torch.FloatTensor(3,4)\n",
    "x2 = torch.FloatTensor(4,5)\n",
    "torch.mm(x1,x2).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "c380153b-e949-4166-8c0d-248d8bdcd504",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 3, 5])"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\" torch.bmm(batch1, batch2) -> batch 단위의 행렬 곱셈 \"\"\"\n",
    "## Tensor(행렬)의 곱을 batch 단위로 처리합니다. torch.mm에서는 단일 Tensor(행렬)로 계산을 한 반면에 batch 단위로 한번에 처리하므로 좀 더 효율적이다.\n",
    "x1 = torch.FloatTensor(10,3,4)\n",
    "x2 = torch.FloatTensor(10,4,5)\n",
    "torch.bmm(x1,x2).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "cf8cda7b-f6bd-4a5f-babc-baaf9d6ae056",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(7)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\" torch.dot(tensor1,tensor2)는 두 tensor의 dot product 연산을 수행한다. \"\"\"\n",
    "## 각 원소끼리 곱한 뒤에 모두 더함\n",
    "torch.dot(torch.tensor([2, 3]), torch.tensor([2, 1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "9583b7cb-cd55-4194-b5e4-1d9c2edba981",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 3])\n",
      "torch.Size([3, 2])\n"
     ]
    }
   ],
   "source": [
    "\"\"\"torch.t()를 이용하면 transposed tensor를 구할 수 있다.\"\"\"\n",
    "x1 = torch.FloatTensor(2,3)\n",
    "x2 = x1.t()\n",
    "print(x1.size())\n",
    "print(x2.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "193e3cea-d726-4a20-9407-c605def5c3ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 3, 5, 4])"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\" torch.transpose()를 이용해서 특정 dimension을 변경할 수 있다. \"\"\"\n",
    "x1 = torch.FloatTensor(10,3,4,5)\n",
    "torch.transpose(x1, 1,2).size()\n",
    "torch.transpose(x1, 2,3).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "3c9a1007-543e-46f4-89b2-00c7bc83a5b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.return_types.eig(\n",
       "eigenvalues=tensor([[0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.]]),\n",
       "eigenvectors=tensor([[1., 0., 0., 0.],\n",
       "        [0., 1., 0., 0.],\n",
       "        [0., 0., 1., 0.],\n",
       "        [0., 0., 0., 1.]]))"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "eigenvalue와 eigenvector를 구하는 방법\n",
    "출력은 각각 eigenvalue와 eigenvector이다.\n",
    "\"\"\"\n",
    "x1 = torch.FloatTensor(4,4)\n",
    "torch.eig(x1,eigenvectors=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch-gpu",
   "language": "python",
   "name": "torch-gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
