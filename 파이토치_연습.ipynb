{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ae01b5b0-1c55-4f8b-8496-574e348397b4",
   "metadata": {},
   "source": [
    "# 텐서 \n",
    "- 텐서는 배열이나 행렬과 매우 유사한 특수한 자료구조입니다. \n",
    "- 텐서는 GPU나 다른 하드웨어 가속기에서 실행할 수 있다는 점만 제외하면 넘파이의 ndarray와 유사합니다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "b0f37b13-697c-46fa-9f80-6829de8aac2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92baa300-59b5-44e9-80a1-e99a4fc47396",
   "metadata": {},
   "source": [
    "### 텐서 초기화\n",
    "- 텐서는 여러가지 방법으로 초기화할 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "d70da38d-42fc-4b98-aaa5-d51b43c0f2f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 2])\n",
      "tensor([[1, 2],\n",
      "        [3, 4]])\n"
     ]
    }
   ],
   "source": [
    "\"\"\"데이터로부터 직접 생성하기\"\"\"\n",
    "## 데이터의 자료형은 자동으로 유추\n",
    "data = [[1,2], [3,4]]\n",
    "x_data = torch.tensor(data)\n",
    "print(x_data.size())\n",
    "print(x_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "577adbc0-0d3a-4048-b297-151b80a9f58d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 2],\n",
       "        [3, 4]], dtype=torch.int32)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"Numpy 배열로부터 생성하기\"\"\"\n",
    "array = np.array(data)\n",
    "x_np = torch.from_numpy(array)\n",
    "x_np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9578db31-7136-48fe-8b73-6ce20edae2c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ones_tensor: \n",
      " tensor([[1, 1],\n",
      "        [1, 1]]) \n",
      "\n",
      "Random tensor: \n",
      " tensor([[0.1312, 0.9483],\n",
      "        [0.4448, 0.4421]]) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "\"\"\"다른 텐서로부터 생성하기\"\"\"\n",
    "## 명시적으로 재정의(override)하지 않는다면, 인자로 주어진 텐서의 속성(shape)과 자료형(datatype)을 유지한다.\n",
    "x_ones = torch.ones_like(x_data) # x_data의 shape을 유지\n",
    "print(f\"ones_tensor: \\n {x_ones} \\n\")\n",
    "\n",
    "# x_data의 자료형은 유지하고, 그 shape을 가지고 random한 수 부여\n",
    "x_rand = torch.rand_like(x_data, dtype=torch.float) # x_data의 shape과 자료형 유지\n",
    "print(f\"Random tensor: \\n {x_rand} \\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "847a08ba-d0ae-4259-a3a0-bd8915d45ba7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rand_tensor: \n",
      " tensor([[0.0682, 0.3449, 0.7785],\n",
      "        [0.8333, 0.5228, 0.9736]]) \n",
      "\n",
      "ones_tensor: \n",
      " tensor([[1., 1., 1.],\n",
      "        [1., 1., 1.]]) \n",
      "\n",
      "zeros_tensor: \n",
      " tensor([[0., 0., 0.],\n",
      "        [0., 0., 0.]]) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "\"\"\"무작위 또는 상수 값을 사용하기\"\"\"\n",
    "## shape은 텐서의 차원을 나타내는 튜플로 아래 함수들에서는 출력 텐서의 차원을 결정\n",
    "shape = (2,3,) # (2,3)이랑 결과가 같음\n",
    "rand_tensor = torch.rand(shape)\n",
    "ones_tensor = torch.ones(shape)\n",
    "zeros_tensor = torch.zeros(shape)\n",
    "\n",
    "print(f\"rand_tensor: \\n {rand_tensor} \\n\")\n",
    "print(f\"ones_tensor: \\n {ones_tensor} \\n\")\n",
    "print(f\"zeros_tensor: \\n {zeros_tensor} \\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30d9e00e-5d1b-4a9d-81f6-75458df44692",
   "metadata": {},
   "source": [
    "------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55d875ba-081a-4fd3-8e3b-664b213e31f8",
   "metadata": {},
   "source": [
    "### 텐서의 속성\n",
    "- 텐서의 속성은 텐서의 shape, datatype 및 어느 device에 저장되는지를 나타낸다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2accc726-5662-417b-99a2-e8de5343f109",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of tensor : torch.Size([3, 4])\n",
      "Datatype of tensor : torch.float32\n",
      "Device of tensor : cpu\n"
     ]
    }
   ],
   "source": [
    "tensor = torch.rand(3,4)\n",
    "print(f\"Shape of tensor : {tensor.shape}\")\n",
    "print(f\"Datatype of tensor : {tensor.dtype}\")\n",
    "print(f\"Device of tensor : {tensor.device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8a8f5ef-d466-409d-ba9b-a10b064a83be",
   "metadata": {},
   "source": [
    "---------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dee8e6e-46a0-49ce-8aec-9f9f160f0ead",
   "metadata": {},
   "source": [
    "### 텐서 연산"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "83890f2a-c12b-47c9-b5fd-1ba51804b190",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"gpu가 존재하면 텐서를 이동\"\"\"\n",
    "if torch.cuda.is_available():\n",
    "    tensor = tensor.to('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b1827a9d-b56f-43a9-ab2d-e69d52aa5cf3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First row: tensor([1., 1., 1., 1.])\n",
      "First col: tensor([1., 1., 1., 1.])\n",
      "last col: tensor([1., 1., 1., 1.])\n",
      "tensor([[1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1.]])\n"
     ]
    }
   ],
   "source": [
    "\"\"\"넘파이 식의 표준 인덱싱과 슬라이싱\"\"\"\n",
    "tensor = torch.ones(4, 4)\n",
    "print(f\"First row: {tensor[0]}\")\n",
    "print(f\"First col: {tensor[:, 0]}\")\n",
    "print(f\"last col: {tensor[..., -1]}\")\n",
    "\n",
    "## 1번째 열을 모두 0으로 만들기\n",
    "tensor[:,1] = 0\n",
    "print(tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "49a75a4b-b9cf-4932-b34c-f1da9936cd4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1.]])\n",
      "torch.Size([12, 4])\n"
     ]
    }
   ],
   "source": [
    "\"\"\"텐서 합치기\"\"\"\n",
    "## torch.cat을 사용하여 주어진 차원에 따라 일련의 텐서 연결\n",
    "## torch.stack도 있음\n",
    "\n",
    "# 1번째 차원으로 concat하기에 (4,4) -> (4,12)가 됨\n",
    "t1 = torch.cat([tensor, tensor, tensor], dim=0)\n",
    "print(t1)\n",
    "print(t1.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "2071c1fd-e7d1-4c97-a0c5-d40151dc4ea4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[1., 0., 1., 1.],\n",
      "         [1., 0., 1., 1.],\n",
      "         [1., 0., 1., 1.],\n",
      "         [1., 0., 1., 1.]],\n",
      "\n",
      "        [[1., 0., 1., 1.],\n",
      "         [1., 0., 1., 1.],\n",
      "         [1., 0., 1., 1.],\n",
      "         [1., 0., 1., 1.]],\n",
      "\n",
      "        [[1., 0., 1., 1.],\n",
      "         [1., 0., 1., 1.],\n",
      "         [1., 0., 1., 1.],\n",
      "         [1., 0., 1., 1.]]])\n",
      "torch.Size([3, 4, 4])\n"
     ]
    }
   ],
   "source": [
    "## torch.cat과 다르게 stack은 차원 자체가 늘어나게 된다.\n",
    "t1 = torch.stack([tensor, tensor, tensor], dim=0)\n",
    "print(t1)\n",
    "print(t1.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f8472852-f512-44f3-a57b-360551304cb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1.]])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[0.8137, 0.2291, 0.3833, 0.2674],\n",
       "        [0.6978, 0.6050, 0.2753, 0.3002],\n",
       "        [0.4532, 0.9711, 0.2018, 0.2027],\n",
       "        [0.2544, 0.3664, 0.3739, 0.5232]])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"산술 연산\"\"\"\n",
    "print(tensor)\n",
    "torch.rand_like(tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "646d2d3a-98da-416f-98be-21394bab7f02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1.]])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[3., 3., 3., 3.],\n",
       "        [3., 3., 3., 3.],\n",
       "        [3., 3., 3., 3.],\n",
       "        [3., 3., 3., 3.]])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"산술 연산\"\"\"\n",
    "## 두 텐서 간의 행렬 곱\n",
    "print(tensor)\n",
    "\n",
    "## 아래의 결과값들은 모두 같다.\n",
    "y1 = tensor@tensor.T\n",
    "y2 = tensor.matmul(tensor.T)\n",
    "\n",
    "# 변수만 지정하고 연산결과를 해당 변수에 저장\n",
    "y3 = torch.rand_like(tensor)\n",
    "torch.matmul(tensor, tensor.T, out=y3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "38f1fd78-e75d-417f-a1c4-3d9fc50b4fcc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 0., 1., 1.],\n",
       "        [1., 0., 1., 1.],\n",
       "        [1., 0., 1., 1.],\n",
       "        [1., 0., 1., 1.]])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## 요소별 곱을 계산\n",
    "## 아래의 결과값들은 모두 같다.\n",
    "\n",
    "z1 = tensor * tensor\n",
    "z2 = tensor.mul(tensor) # 같은 값을 두 번 곱하면 하나만 써주기\n",
    "\n",
    "z3 = torch.rand_like(tensor)\n",
    "torch.mul(tensor, tensor, out=z3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "b4cdf2b3-e608-4984-8a9c-1a78f7a3518d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(12.)\n",
      "\n",
      "12.0    <class 'float'>\n"
     ]
    }
   ],
   "source": [
    "\"\"\"단일 요소 텐서: .item()\"\"\"\n",
    "## 텐서의 모든 값을 하나로 집계하여 요소가 하나인 텐서의 경우, item()을 사용하여 python 숫자 값으로 반환할 수 있다.\n",
    "agg = tensor.sum()\n",
    "print(agg)\n",
    "print()\n",
    "\n",
    "agg_item = agg.item()\n",
    "print(agg_item,'  ', type(agg_item))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "4b26a826-adaf-46d4-affd-206433ae449a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[6., 5., 6., 6.],\n",
      "        [6., 5., 6., 6.],\n",
      "        [6., 5., 6., 6.],\n",
      "        [6., 5., 6., 6.]]) \n",
      "\n",
      "tensor([[11., 10., 11., 11.],\n",
      "        [11., 10., 11., 11.],\n",
      "        [11., 10., 11., 11.],\n",
      "        [11., 10., 11., 11.]])\n"
     ]
    }
   ],
   "source": [
    "\"\"\"바꿔치기 연산: 모든 element들에 지정된 수 연산하기\"\"\"\n",
    "## 연산 결과를 피연산자에 저장하는 연산을 바꿔치기 연산이라고 부르며 _접미사를 갖는다.\n",
    "    # x.copy_(y)나 x.t_()는 x를 변경\n",
    "print(f\"{tensor} \\n\")\n",
    "tensor.add_(5)\n",
    "print(tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd260dcc-f26a-4c9c-b299-fb703836bd90",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a84646ce-c0d3-450a-a2ed-c92f169a25fd",
   "metadata": {},
   "source": [
    "# Numpy 변환\n",
    "- cpu 상의 텐서와 넘파이 배열은 메모리 공간을 공유하기 때문에, 하나를 변경하면 다른 하나도 변경된다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "d65c732e-427b-4285-9e7c-45edb3dfeb90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t: tensor([1., 1., 1., 1., 1.])\n",
      "n: [1. 1. 1. 1. 1.]\n"
     ]
    }
   ],
   "source": [
    "\"\"\"텐서를 넘파이 배열로 변경하기 : .numpy()\"\"\"\n",
    "t = torch.ones(5)\n",
    "print(f\"t: {t}\")\n",
    "\n",
    "n = t.numpy()\n",
    "print(f\"n: {n}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "e94b4d7e-1c7a-43f2-b1d3-8367840ef2fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t: tensor([2., 2., 2., 2., 2.])\n",
      "n: [2. 2. 2. 2. 2.]\n"
     ]
    }
   ],
   "source": [
    "### 텐서의 변경 사항이 넘파이 배열에 반영되는 것 확인\n",
    "t.add_(1)\n",
    "\n",
    "## 넘파이와 텐서 모두 바뀐 것을 확인\n",
    "print(f\"t: {t}\")\n",
    "print(f\"n: {n}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "64e9d438-adad-4220-a667-fe9271212ac6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"넘파이 배열을 텐서로 변경하기 : .from_numpy() \"\"\"\n",
    "## 넘파이 및 텐서 지정\n",
    "n  = np.ones(5)\n",
    "t = torch.from_numpy(n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "6a285f4a-4132-4526-92d7-059d3b110101",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t : tensor([3., 3., 3., 3., 3.], dtype=torch.float64)\n",
      "n : [3. 3. 3. 3. 3.]\n"
     ]
    }
   ],
   "source": [
    "## 넘파이 배열의 변경 사항이 텐서에 반영\n",
    "np.add(n, 1, out=n) # out으로 출력할 변수명을 적어주거나 새롭게 변수에 할당시키기\n",
    "print(f\"t : {t}\")\n",
    "print(f\"n : {n}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch-gpu",
   "language": "python",
   "name": "torch-gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
