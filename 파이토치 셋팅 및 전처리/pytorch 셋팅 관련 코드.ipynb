{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f32d2833-faaf-488e-894f-3d86373e6feb",
   "metadata": {},
   "source": [
    "## pytorch import 모음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e373e7b8-7392-44f9-b7ad-26afb80b3874",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn ## neural network 모음 (nn.Linear, nn.conv2d, Batchnorm, Loss functions 등)\n",
    "import torch.optim as optim ## optimization algorithm 모음 (SGD, Adam)\n",
    "import torch.nn.functional as F ## 파라미터가 필요없는 Function 모음\n",
    "from torch.utils.data import DataLoader ## 데이터 세트 관리 및 미니 배치 생성을 위한 함수 모음\n",
    "import torchvision.datasets as datasets ## 표준 데이터 세트 모음\n",
    "import torchvision.transforms as transforms ## 데이터 세트에 적용 할 수 있는 변환 관련 함수 모음\n",
    "from torch.utils.tensorboard import SummaryWriter ## tensorboard에 출력하기 위한 함수 모음\n",
    "import torch.backends.cudnn as cudnn ## cudnn을 다루기 위한 값 모음\n",
    "from torchsummary import summary ## summary를 통한 model의 현황을 확인 하기 위함\n",
    "import torch.onnx ## model을 onnx로 변환하기 위함"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "717a97b2-a8c2-4b9f-84fe-7a6bbbb310bf",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "164df1f5-c3f5-4cba-b93d-fb3d290d5f0a",
   "metadata": {},
   "source": [
    "## pytorch 셋팅 관련 코드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "272f73c0-cb82-4720-8893-2824663c45a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "## pytorch 내부적으로 사용하는 seed 값 설정\n",
    "seed = 42\n",
    "torch.manual_seed(seed)\n",
    "\n",
    "## cuda를 사용할 경우 pytorch 내부적으로 사용하는 seed 값 설정\n",
    "torch.cuda.manual_seed(seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29f2f410-dd9c-4bbe-b8f5-fe997357ea22",
   "metadata": {},
   "source": [
    "-----"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3db5065-ea58-46a2-b6c2-e7298c198e58",
   "metadata": {},
   "source": [
    "## GPU 셋팅 관련 코드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "64f0f189-5937-464f-b03a-19d1f7b2c0d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "## cuda가 사용 가능한 지 확인\n",
    "torch.cuda.is_available()\n",
    "\n",
    "## cuda가 사용 가능하면 device에 \"cuda\"를 저장하고 사용 가능하지 않으면 \"cpu\"를 저장한다.\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "\n",
    "## 멀티 GPU 사용 시 device에 \"cuda\"를 저장하고 사용 가능하지 않으면 \"cpu\"를 저장한다.\n",
    "    # 아래 코드의 '0', '1', '2'는 gpu가 3개 있고 그 번호가 0,1,2인 상황의 예제\n",
    "    # 만약 GPU가 5개이고 사용 가능한 것이 0, 3, 4라면 \"0,3,4\"라고 적으면 된다.\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \",\".join(list(map(str, list(range(torch.cuda.device_count())))))\n",
    "\n",
    "## cudnn을 사용하도록 설정. GPU를 사용하고 있으면 기본값을 True이다.\n",
    "import torch.backends.cudnn as cudnn\n",
    "cudnn.enabled = True\n",
    "\n",
    "## inbuilt cudnn auto-tuner 사용 중인 hardware에 가장 적합한 알고리즘을 선택하도록 허용한다.\n",
    "cudnn.benchmark = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "580fee68-7ecb-48f0-8bb4-e0c9e0b6abf9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11.0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"GPU device의 사용 가능한 메모리를 코드 상에서 확인하려면 아래 함수를 사용한다.\"\"\"\n",
    "## unit : byte\n",
    "torch.cuda.get_device_properties(\"cuda:0\").total_memory\n",
    "\n",
    "## unit : mega byte\n",
    "torch.cuda.get_device_properties(\"cuda:0\").total_memory // 1e6\n",
    "\n",
    "## unit : giga byte\n",
    "torch.cuda.get_device_properties(\"cuda:0\").total_memory // 1e9"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f23ec75-9ce9-4ccb-a204-bff83aad9bd9",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad7da81d-b167-49b9-9aef-475a6c3f6636",
   "metadata": {},
   "source": [
    "## dataloader의 num_workers 지정\n",
    "- pytorch를 이용하여 학습을 할 때, 데이터를 불러오는 방법으로 DataLoader(from torch.utils.data_import DataLoader)를 사용한다.\n",
    "- DataLoader의 `num_workers는 cpu -> gpu로 데이터를 로드할 때 사용하는 프로세스의 갯수`를 뜻한다.\n",
    "- 컴퓨터에서 병목 현상이 발생하는 대표적인 구간이 바로 I/O(input/output) 연산이다. 따라서 I/O 연산에 최대 사용할 수 있는 `코어를 적당하게 나누어 주어서 병목 현상을 제거하는 것이 전체 학습 시간을 줄일 수 있는 데 도움`이 된다.\n",
    "- num_workers=0이 기본적으로 사용된다. 이 옵션의 의미는 data loading이 오직 main process에서만 발생하도록 하는 synchronous 방법을 의미한다.\n",
    "- 따라서 `num_workers>0 조건이 되도록 설정하여 asynchronous 하게 data loading이 가능`해지기 때문에, GPU 연산과 병렬적으로 data loading이 가능해지게 되어 병목 문제를 개선할 수 있다.\n",
    "- num_workers 갯수로는 휴리스틱하게 결정하는 데 실험적으로 접근해 본 한 사람의 의견으로는 num_workers=4*GPU이다.\n",
    "- 이후 연습에서는 위에서 말한 관계식처럼 num_workers = torch.cuda.device_count()*4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b845f39-85e4-4c5c-b5e9-e7680cf05e91",
   "metadata": {},
   "source": [
    "### dataloader의 pin_memory\n",
    "- torch.utils.data.DataLoader()를 사용할 때, 옵션으로 `pin_memory=True`라는 것이 있다. pin_memory는 고정된 메모리로 default는 False이다. 이 옵션의 의미는 `cpu -> gpu로의 메모리 복사 시 오직 main process에서만 복사가 발생하도록 하는 synchronous 방법`을 의미한다. 하드웨어 자원이 많을 때 궂이 하나의 프로세스에서만 작업하는 것은 비효율적이다.\n",
    "- `pin_memory=True로 설정하면 학습 중에 cpu가 데이터를 gpu로 전달하는 속도를 향상시킨다.` 따라서 이 옵션은 gpu를 사용하여 학습할 때에는 항상 사용한다고 보면 된다.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c24376d3-6725-45ad-9acf-f5c4473d14f0",
   "metadata": {},
   "source": [
    "------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12fa3bc8-d7df-4a51-a274-8a8f9aaaec9e",
   "metadata": {},
   "source": [
    "### GPU 사용 시 data.cuda(non_blocking=True) 사용\n",
    "- gpu를 이용하여 학습할 때, 바로 앞의 dataloader의 pin_memory 사용과 더불어 data의 .cuda(non_blocking=True)는 일반적으로 반드시 사용하는 옵션이다.\n",
    "- 이 옵션은 cpu->gpu로 데이터를 전달하는 메커니즘과 연관된 옵션이다.\n",
    "- 텐서 및 스토리지를 고정하면 비동기(asynchronous) GPU 복사본을 사용할 수 있다. 비동기식으로 GPU에 데이터 전달 기능을 추가하려면 non_blocking=True를 to() 또는 cuda() 호출 시 argument로 전달하면 된다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0665d3a-fee3-463a-a37e-97ec587ddac7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch-gpu",
   "language": "python",
   "name": "torch-gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
